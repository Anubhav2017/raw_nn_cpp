{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D,Conv1D, MaxPooling1D,Reshape, LSTM, Dropout, TimeDistributed, Input\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fxpmath import Fxp\n",
    "import numpy as np\n",
    "\n",
    "class Converter():\n",
    "\n",
    "    def encode(self, input_data, signed=True, total_bits=16, fractional_bits=13):\n",
    "        '''\n",
    "\n",
    "        Converts input data from float/int python data types to ap_fixed with total bits and fractional_bits and returns its uint32 equivalent\n",
    "\n",
    "        :param input_data: can be both a single int/float number or a numpy array\n",
    "        :param signed: Boolean, if the input data is signed or not\n",
    "        :param total_bits: numer of total bits used to represent the input data\n",
    "        :param fractional_bits: number of fractional bits used to represent the input data. Integer bits = total bits - fractional bits\n",
    "        :return: input data converted to uint32 format. 0.5 can be represented with 4 bits as 0.100. This is converted into 0100 (fractional point removed) and then converted to int.\n",
    "                 0.5 as input is converted to 4 as uint32.\n",
    "\n",
    "        '''\n",
    "        fixed_point_representation = Fxp(input_data, signed=signed, n_word = total_bits, n_frac = fractional_bits)\n",
    "        uint_coverted = np.uint32(fixed_point_representation.uraw())\n",
    "        return uint_coverted\n",
    "\n",
    "\n",
    "\n",
    "    def decode(self, input_data, total_bits=16, fractional_bits=13):\n",
    "        '''\n",
    "        Converts input data from uint32 format to float with total_bits and fractional_bits resolution\n",
    "\n",
    "        :param input_data: can be both a single int/float number or a numpy array\n",
    "        :param total_bits: numer of total bits used to represent the input data\n",
    "        :param fractional_bits: number of fractional bits used to represent the input data. Integer bits = total bits - fractional bits\n",
    "        :return: converted input data from uint32 to float\n",
    "        '''\n",
    "\n",
    "        if type(input_data) is not np.ndarray:\n",
    "            input_data = np.array([input_data])\n",
    "\n",
    "        #Function taken from here: https://discuss.pynq.io/t/how-to-use-ap-fixed-data-type-to-communicate-with-the-ip-made-by-the-vivado-hls/679/5\n",
    "        condition = 1 << (total_bits - 1)\n",
    "        mask = (~((1 << total_bits) - 1)) & 0xFFFFFFFF\n",
    "        return np.where(input_data < condition, input_data, (input_data.view('u4') | mask).view('i4')) / (1 << fractional_bits)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=Converter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.load(\"x_train_plain.npy\")\n",
    "y_train=np.load(\"y_train.npy\")\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=x_train.reshape((-1,784,1))/255.0\n",
    "# x_test=x_test.reshape((-1,784,1))/255.0\n",
    "# y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "# x_train=x_train[idx]\n",
    "# y_train=y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train=x_train.reshape((-1,784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-30 12:25:31.427942: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-05-30 12:25:31.428179: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-30 12:25:31.429082: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "model.add(Input(shape=(784,)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=10))\n",
    "model.compile( loss='categorical_crossentropy', metrics=['accuracy'], optimizer=SGD(learning_rate=0.01))\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.load(\"w1.npy\")\n",
    "w2=np.load(\"w2.npy\")\n",
    "b1=np.load(\"b1.npy\")\n",
    "b2=np.load(\"b2.npy\")\n",
    "\n",
    "w1= converter.decode(w1)\n",
    "w2= converter.decode(w2)\n",
    "b1= converter.decode(b1)\n",
    "b2= converter.decode(b2)\n",
    "\n",
    "weights1=[w1,b1]\n",
    "weights2=[w2,b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=w1.reshape(64,784)\n",
    "print(w1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights(weights1)\n",
    "model.layers[1].set_weights(weights2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model.predict(x_train[:1])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    t0=time.time()\n",
    "\n",
    "    y_pred=model(x_train[:1])\n",
    "    t1=time.time()\n",
    "    \n",
    "    # print(y_pred)\n",
    "    loss=tf.keras.losses.MeanSquaredError()(y_train,y_pred)\n",
    "    t2=time.time()\n",
    "    # print(loss)\n",
    "\n",
    "grads=tape.gradient(loss,model.trainable_variables)\n",
    "t3=time.time()\n",
    "\n",
    "optimizer.apply_gradients(zip(grads,model.trainable_variables))\n",
    "t4=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0012159347534179688\n"
     ]
    }
   ],
   "source": [
    "print(t4-t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=model.layers[0].weights[0].numpy()\n",
    "w2=model.layers[1].weights[0].numpy()\n",
    "b1=model.layers[0].weights[1].numpy()\n",
    "b2=model.layers[1].weights[1].numpy()\n",
    "\n",
    "print(w1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter=Converter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1_encoded=converter.encode(w1)\n",
    "w2_encoded=converter.encode(w2)\n",
    "b1_encoded=converter.encode(b1)\n",
    "b2_encoded=converter.encode(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(w1_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"w1.txt\",\"w\")\n",
    "for i in range(64):\n",
    "    for j in range(784):\n",
    "        f.write(f\"{w1[j][i]}\"+\" \")\n",
    "f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"b1.txt\",\"w\")\n",
    "for i in range(64):\n",
    "    f.write(f\"{b1[i]}\"+\" \")\n",
    "f.close()\n",
    "\n",
    "f=open(\"b2.txt\",\"w\")\n",
    "for i in range(10):\n",
    "    f.write(f\"{b2[i]}\"+\" \")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"w2.txt\",\"w\")\n",
    "for i in range(10):\n",
    "    for j in range(64):\n",
    "        f.write(f\"{w2[j][i]}\"+\" \")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('w1.npy',w1_encoded, dtype=\"uint16\")\n",
    "np.save('w2.npy',w2_encoded, dtype=\"uint16\")\n",
    "np.save('b1.npy',b1_encoded, dtype=\"uint16\")\n",
    "np.save('b2.npy',b2_encoded, dtype=\"uint16\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d13be26f8f2314f08ea17dd6124c560f7ae3942ec34d11c0cd23e14a586fdbbb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('genomics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
